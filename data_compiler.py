# file_parsers.py
from emoji_data.data_dict import EMOJI_DATA, CATEGORIES, LANGUAGES
from emoji_data.data_dict_legacy import LEGACY_EMOJI_DATA
from core import is_emoji
import xml.etree.ElementTree as ET
import unicodedata
import requests
import bs4
import os
import re

def _get_text_from_url(url: str) -> str:
    """Get text from url"""
    return requests.get(url).text

def adapt_emoji_name(text: str, lang: str, emj: str) -> str:
    # Use NFKC-form (single character instead of character + diacritic)
    # Unicode.org files should be formatted like this anyway, but emojiterra is not consistent
    text = unicodedata.normalize('NFKC', text)

    # Fix German clock times "12:30 Uhr" -> "12.30 Uhr"
    text = re.sub(r"(\d+):(\d+)", r"\1.\2", text)

    # Remove white space
    text = "_".join(text.split(" "))

    emoji_name = ":" + (
        text
        .lower()
        .removeprefix("flag:_")
        .replace(":", "")
        .replace(",", "")
        .replace('"', "")
        .replace("\u201e", "")
        .replace("\u201f", "")
        .replace("\u202f", "")
        .replace("\u229b", "")
        .replace("\u2013", "-")
        .replace(",_", ",")
        .strip()
        .replace(" ", "_")
        .replace("_-_", "-")
    ) + ":"

    if lang == "de":
        emoji_name = emoji_name.replace("\u201c", "").replace("\u201d", "")
        emoji_name = re.sub(r"(hautfarbe)_und_([a-z]+_hautfarbe)", r"\1,\2", emoji_name)

    if lang == "fa":
        emoji_name = emoji_name.replace('\u200c', "_")
        emoji_name = emoji_name.replace('\u200f', "_")
        emoji_name = emoji_name.replace('\u060c', "_")
        emoji_name = re.sub("_+", "_", emoji_name)

    if lang == "zh":
        emoji_name = ":" + (
            text
            .replace(":", "")
            .replace(",", "")
            .replace('-', "")
            .replace("\u201e", "")
            .replace("\u201f", "")
            .replace("\u202f", "")
            .replace("\u229b", "")
            .replace(",_", ",")
            .strip()
            .replace(" ", "_")
        ) + ":"

        if 'Êó•Êñá' in emoji_name:
            # Japanese buttons
            emoji_name = emoji_name.replace('Êó•ÊñáÁöÑ', '').replace('ÊåâÈíÆ', '').replace('‚Äú', '').replace('‚Äù', '')

        if 'ÁÆ≠Â§¥' in emoji_name:
            # Arrows
            emoji_name = emoji_name.replace('_', '').replace('!', '')

        if 'ÊåâÈíÆ' in emoji_name:
            # English buttons
            emoji_name = emoji_name.replace('_', '')

        if 'ÂûãË°Ä' in emoji_name:
            emoji_name = emoji_name.replace('_', '')

        if '‰∏≠Á≠â-' in emoji_name:
            emoji_name = emoji_name.replace('‰∏≠Á≠â-', '‰∏≠Á≠â')

        if emoji_name.startswith(':Êóó_'):
            # Countries
            emoji_name = emoji_name.replace(':Êóó_', ':')

        hardcoded = {
            '\U0001f1ed\U0001f1f0': ':È¶ôÊ∏Ø:',  # üá≠üá∞
            '\U0001f1ee\U0001f1e9': ':Âç∞Â∫¶Â∞ºË•ø‰∫û:',  # üáÆüá©
            '\U0001f1f0\U0001f1ff': ':ÂìàËñ©ÂÖã:',  # üá∞üáø
            '\U0001f1f2\U0001f1f4': ':Êæ≥ÈñÄ:',  # üá≤üá¥
            '\U0001f1e8\U0001f1ec': ':ÂàöÊûú_Â∏É:',  # üá®üá¨
            '\U0001f1e8\U0001f1e9': ':ÂàöÊûú_Èáë:',  # üá®üá©
            '\U0001f193': ':FREEÊåâÈíÆ:',  # üÜì
            '\U0001f238': ':Áî≥:',  # üà∏
            '\U0001f250': ':Âæó:',  # üâê
            '\U0001f22f': ':Êåá:',  # üàØ
            '\U0001f232': ':Á¶Å:',  # üà≤
            '\u3297\ufe0f': ':Á•ù:',  # „äóÔ∏è
            '\u3297': ':Á•ù:',  # „äó
            '\U0001f239': ':Ââ≤:',  # üàπ
            '\U0001f21a': ':Êó†:',  # üàö
            '\U0001f237\ufe0f': ':Êúà:',  # üà∑Ô∏è
            '\U0001f237': ':Êúà:',  # üà∑
            '\U0001f235': ':Êª°:',  # üàµ
            '\U0001f236': ':Êúâ:',  # üà∂
            '\U0001f234': ':Âêà:',  # üà¥
            '\u3299\ufe0f': ':Áßò:',  # „äôÔ∏è
            '\u3299': ':Áßò:',  # „äô
            '\U0001f233': ':Á©∫:',  # üà≥
            '\U0001f251': ':ÂèØ:',  # üâë
            '\U0001F23A': ':Ëê•:',  # üà∫
            '\U0001F202\ufe0f': ':ÊúçÂä°:',  # üàÇÔ∏è
            '\U0001F202': ':ÊúçÂä°:',  # üàÇ
        }

        if emj in hardcoded:
            emoji_name = hardcoded[emj]

    emoji_name = (emoji_name
        .replace("____", "_")
        .replace("___", "_")
        .replace("__", "_")
        .replace("--", "-"))

    return emoji_name

def get_emojiterra_from_url(url: str) -> dict:
    html = _get_text_from_url(url)

    soup = bs4.BeautifulSoup(html, "html.parser")
    emojis = {}

    data = soup.find_all('li')
    data = [i for i in data if 'href' not in i.attrs and 'data-e' in i.attrs and i['data-e'].strip()]

    for i in data:
        code = i['data-e']
        emojis[code] = i['title'].strip()

    assert len(data) > 100, f"emojiterra data from {url} has only {len(data)} entries"

    return emojis

def get_cheat_sheet(url: str) -> dict:
    """
    Returns a dict of emoji to short-names:
    E.g. {'üë¥': ':old_man:', 'üëµ': ':old_woman:', ... }
    """

    html = _get_text_from_url(url)

    soup = bs4.BeautifulSoup(html, "html.parser")
    emojis = {}

    items = soup.find(class_='ecs-list').find_all(class_='_item')

    pattern = re.compile(r'U\+([0-9A-F]+)')

    for i in items:
        unicode_text = i.find(class_='unicode').text

        code_points = pattern.findall(unicode_text)
        code = ''.join(chr(int(x,16)) for x in code_points)

        emojis[code] = i.find(class_='shortcode').text

    # Remove some unwanted and some weird entries from the cheat sheet
    filtered = {}
    for emj, short_code in emojis.items():

        if short_code.startswith(':flag_'):
            # Skip flags from cheat-sheet, because we already have very similar aliases for the flags
            continue

        if '‚äõ' in short_code:
            # Strange emoji with ‚äõ in the short-code
            continue

        if emj == '\U0001F93E\U0000200D\U00002640\U0000FE0F':
            # The short-code for this emoji is wrong
            continue

        if emj == '\U0001F468\U0000200D\U0001F468\U0000200D\U0001F467':
            # The short-code for this emoji is wrong
            continue

        if short_code.startswith('::'):
            # Do not allow short-codes to have double :: at the start
            short_code = short_code[1:]

        if short_code.endswith('::'):
            # Do not allow short-codes to have double :: at the end
            short_code = short_code[:-1]

        filtered[emj] = short_code

    assert len(filtered) > 100, f"emoji-cheat-sheet data from {url} has only {len(filtered)} entries"

    return filtered

def get_emoji_from_youtube(url: str) -> dict:
    """Get emoji alias from Youtube
    Returns a dict of emoji to list of short-names:
    E.g. {'üíÅ': [':person_tipping_hand:', ':information_desk_person:'], 'üòâ': [':winking_face:', ':wink:']}
    """

    data = requests.get(url).json()

    output = {}
    for obj in data:
        if 'shortcuts' not in obj or 'emojiId' not in obj:
            continue

        shortcuts = [x for x in obj['shortcuts'] if x.startswith(':') and x.endswith(':')]

        if shortcuts:
            output[obj['emojiId']] = shortcuts

    assert len(output) > 100, f"youtube data from {url} has only {len(output)} entries"

    return output

def extract_emojis(emojis_lines: list, sequences_lines: list) -> dict:
    """Extract emojis line by line to dict"""

    output = {}
    for line in emojis_lines:
        if not line == "" and not line.startswith("#"):
            emoji_status = line.split(";")[1].strip().split(" ")[0]

            codes = line.split(";")[0].strip().split(" ")
            separated_line = line.split(" # ")[-1].strip().split(" ")
            separated_name = separated_line[2:]
            version_str = separated_line[1]
            emoji_name = (
                "_".join(separated_name)
                .removeprefix("flag:_")
                .replace(":", "")
                .replace(",", "")
                .replace("\u201c", "")
                .replace("\u201d", "")
                .replace("\u229b", "")
                .strip()
                .replace(" ", "_")
                .replace("_-_", "-")
            )

            emoji_code = "".join(
                [
                    "\\U0000" + code if len(code) == 4 else "\\U000" + code
                    for code in codes
                ]
            )

            version = float(version_str.replace("E", "").strip())

            if emoji_code in output:
                raise Exception("Duplicate emoji: " +
                                emoji_name + " " + emoji_code)

            output[emoji_code] = {
                "en": emoji_name,
                "status": emoji_status.replace("-", "_"),
                "version": version
            }

    # Walk through the emoji-variation-sequences.txt
    for line in sequences_lines:
        if not line == "" and not line.startswith("#"):
            # No variant
            normal_codes = line.split(";")[0].strip().split(" ")
            normal_code = "".join(
                [
                    "\\U0000" + code if len(code) == 4 else "\\U000" + code
                    for code in normal_codes
                ]
            )
            if normal_code in output:
                output[normal_code]["variant"] = True

            # Text variant U+FE0E
            text_codes = re.sub(r'\s*FE0E\s*$', '',
                                line.split(";")[0]).strip().split(" ")
            text_code = "".join(
                [
                    "\\U0000" + code if len(code) == 4 else "\\U000" + code
                    for code in text_codes
                ]
            )
            if text_code in output:
                output[text_code]["variant"] = True

            # Emoji variant U+FE0F
            emoji_codes = re.sub(r'\s*FE0F\s*$', '', line.split(";")[0]).strip().split(" ")
            emoji_code = "".join(
                [
                    "\\U0000" + code if len(code) == 4 else "\\U000" + code
                    for code in emoji_codes
                ]
            )
            if emoji_code in output:
                output[emoji_code]["variant"] = True

    return output

def add_unicode_annotations(data, lang, url):
    xml = _get_text_from_url(url)

    tree = ET.fromstring(xml)
    annotations = tree.find('annotations')
    for annotation in annotations:
        if annotation.get('type') == 'tts':
            emj = annotation.get('cp')
            text = annotation.text.strip()

            emoji_name = adapt_emoji_name(text, lang, emj)

            if emj in data and data[emj] != emoji_name:
                print(
                    f"# {lang}: CHANGED {data[emj]} TO {emoji_name} \t\t(Original: {text})")
            data[emj] = emoji_name

def extract_names(github_tag, github_lang, lang, emoji_terra={}):
    """Copies emoji.EMOJI_DATA[emj][lang] and adds the names from the Unicode CLDR xml

    Find latest tag at https://cldr.unicode.org/index/downloads or
    https://github.com/unicode-org/cldr/tree/main/common/annotations
    """

    data = _translate_emoji_name(lang)
    add_unicode_annotations(data, lang, f"https://github.com/unicode-org/cldr/raw/{github_tag}/common/annotations/{github_lang}.xml")
    add_unicode_annotations(data, lang, f"https://github.com/unicode-org/cldr/raw/{github_tag}/common/annotationsDerived/{github_lang}.xml")

    # Add names from emojiterra if there is no unicode annotation
    for emj, name in emoji_terra.items():
        if emj in EMOJI_DATA and emj not in data:
            emoji_name = adapt_emoji_name(name, lang, emj)
            data[emj] = emoji_name

    # There are some emoji with two code sequences for the same emoji, one that ends with \uFE0F and one that does not.
    # The one that ends with \uFE0F is the "new" emoji, that is RGI.
    # The Unicode translation data sometimes only has one of the two code sequences and is missing the other one.
    # In that case we want to use the existing translation for both code sequences.
    missing_translation = {}
    for emj in data:
        if emj.endswith('\uFE0F') and emj[0:-1] not in data and emj[0:-1] in EMOJI_DATA:
            # the emoji NOT ending in \uFE0F exists in EMOJI_DATA but is has no translation
            # e.g. ':pirate_flag:' -> '\U0001F3F4\u200D\u2620\uFE0F' or '\U0001F3F4\u200D\u2620'
            missing_translation[emj[0:-1]] = data[emj]

        with_emoji_type = f"{emj}\uFE0F"
        if not emj.endswith('\uFE0F') and with_emoji_type not in data and with_emoji_type in EMOJI_DATA:
            # the emoji ending in \uFE0F exists in EMOJI_DATA but is has no translation
            # e.g. ':face_in_clouds:' -> '\U0001F636\u200D\U0001F32B\uFE0F' or '\U0001F636\u200D\U0001F32B'
            missing_translation[with_emoji_type] = data[emj]

    # Find emoji that contain \uFE0F inside the sequence (not just as a suffix)
    # e.g. ':eye_in_speech_bubble:' -> '\U0001F441\uFE0F\u200D\U0001F5E8\uFE0F'
    for emj in EMOJI_DATA:
        if emj in data:
            continue
        emj_no_variant = emj.replace('\uFE0F', '')
        if emj_no_variant != emj and emj_no_variant in data:
            # the emoji with \uFE0F has no translation, but the emoji without all \uFE0F has a translation
            data[emj] = data[emj_no_variant]

    data.update(missing_translation)

    return data

def get_emoji_from_github_api(url: str) -> dict:
    """Get emoji alias from GitHub API
    """

    data = requests.get(url).json()
    pattern = re.compile(r"unicode/([0-9a-fA-F-]+)\.[a-z]+")

    output = {}
    for name, img in data.items():
        m = pattern.search(img)
        if m:
            emj = "".join(chr(int(h, 16)) for h in m.group(1).split('-'))
            output[name] = emj
        else:
            pass  # Special GitHub emoji that is not part of Unicode

    assert len(output) > 100, f"data from github API has only {len(output)} entries"

    return output

def find_github_aliases(emj, github_dict, v, emj_no_variant=None):
    aliases = set()

    # Strip ZWJ \u200D, text_type \uFE0E and emoji_type \uFE0F
    # because the GitHub API does not include these
    emj_clean = GITHUB_REMOVED_CHARS.sub("", emj)

    for gh_alias in github_dict:
        if emj == github_dict[gh_alias]:
            aliases.add(gh_alias)
        elif 'variant' in v and emj_no_variant == github_dict[gh_alias]:
            aliases.add(gh_alias)
        elif emj_clean == github_dict[gh_alias]:
            aliases.add(gh_alias)

    return aliases

##############################################################

_CURRENT_PATH = os.path.dirname(os.path.realpath(__file__))
GITHUB_REMOVED_CHARS = re.compile("\u200D|\uFE0F|\uFE0E", re.IGNORECASE)
github_alias_dict = get_emoji_from_github_api('https://api.github.com/emojis')
cheat_sheet_dict = get_cheat_sheet('https://www.webfx.com/tools/emoji-cheat-sheet/')
youtube_dict = get_emoji_from_youtube('https://www.gstatic.com/youtube/img/emojis/emojis-png-7.json')

def _create_data_file(path: str):
    if os.path.exists(path):
        with open(path, 'w') as file:
            file.close()
            return True
    with open(path, 'x') as file:
        file.close()
        return True 

def _write_data(data: str, output_file: str):
    if os.path.exists(output_file):
        with open(output_file, "a", encoding="utf-8") as outfile:
            outfile.write(data)
            outfile.close()
            return True
    return False  

def _unicode(emojis):
    emoji_string = emojis
    unicode_values = []
    for i in range(0, len(emoji_string)):
        unicode_values.append(ord(emoji_string[i].encode('utf-16', 'surrogatepass').decode('utf-16')))
    unicode_strings = []
    for codepoint in unicode_values:
        unicode_strings.append(f"U+{codepoint:04X}")        
    return unicode_strings

def _escape_sequence(emoji):
    escape_sequence = f""
    if emoji is not None:
        if len(emoji) > 1:
            for i, char in enumerate(emoji):
                unicode_code_point = ord(emoji[i])
                escape_sequence += f"\\U{unicode_code_point:08X} "
            return escape_sequence  
        unicode_code_point = ord(emoji[0])
        escape_sequence = f"\\U{unicode_code_point:08X}"
        return escape_sequence

def _ascii(s):
    # return escaped Code points \U000AB123
    return s.encode("unicode-escape").decode()

def _translate_emoji_name(lang):
    data = {emj: EMOJI_DATA[emj][lang] for emj in EMOJI_DATA if lang in EMOJI_DATA[emj]}
    return data
    
def _get_text_from_url(url: str) -> str:
    """Get text from url"""
    return requests.get(url).text

def _in_emoji_data(emoji):
    return emoji in EMOJI_DATA

def get_unicode_emoji_variation_sequence_file(version: str) -> list:
    """Get splitlines of emoji variation sequences from unicode.org"""

    url = f"https://www.unicode.org/Public/{version}/ucd/emoji/emoji-variation-sequences.txt"
    return _get_text_from_url(url).splitlines()

def get_unicode_emoji_test_file(version: float) -> list:
    """Get splitlines of emojis list from unicode.org"""
    url = f"https://unicode.org/Public/emoji/{version}/emoji-test.txt"
    return _get_text_from_url(url).splitlines()

def extract_unused_github_emojis() -> dict:
    ghemojis = {}
    for key in github_alias_dict.keys():
        emoji = github_alias_dict[key]
        emoji_name = key
        if not _in_emoji_data(emoji):
            ghemojis[emoji] = emoji_name   
    return ghemojis

def extract_emoji_data():
    
    """
    Extracts emoji data line by line to dict
    
    This function parses the emoji-test.txt file found on Unicode.org at
    https://unicode.org/Public/emoji/latest/emoji-test.txt
    
    This function generates a string representation of a dictionary containing 
    the data from the emoji-test.txt file for each emoji and yields the dict 
    representation string to be printed or written to file. Each yield is used 
    to construct the EMOJI_DATA dictionary in data_dict.py 
    
    Each emoji is stored in a dictionary with the following keys and value
    types:
    
    "\U0001F600": {  # üòÄ
        "index": 1,                        int
        "category": "Smileys & Emotion",      str
        "subcategory": "face-smiling",        str
        "status": fully_qualified,         int
        "emoji": "üòÄ",                     str
        "E": 1.0,                          float
        "unicodes": ['U+1F600'],           list
        "codepoints": ['1F600'],           list
        "sequences": ['\\U0001F600'],      list
        "category": "So",                  str
        "name": ":grinning_face:",         str
        "en": ":grinning_face:",           str
        "es": ":cara_sonriendo:",              
        "ja": ":„Å´„Å£„Åì„ÇäÁ¨ë„ÅÜ:",
        "ko": ":ÌôúÏßù_ÏõÉÎäî_ÏñºÍµ¥:",
        "pt": ":rosto_risonho:",
        "it": ":faccina_con_un_gran_sorriso:",
        "fr": ":visage_rieur:",
        "de": ":grinsendes_gesicht:",
        "fa": ":ÿÆŸÜÿØŸá:",
        "id": ":wajah_gembira:",
        "zh": ":ÂòøÂòø:",
    """
   
    current_category = None
    current_subcategory = None
    current_category_id = None
    current_subcategory_id = None
    current_status = None
    current_codepoints = None
    current_emoji = None
    current_version = None
    current_emoji_name = None
    current_emoji_alias = None
    is_emoji_variant = False
    real_index = 0
    
    #//////////// UNICODE EMOJI-TEST.TXT //////
    for current_line, line in enumerate(get_unicode_emoji_test_file(15.0)):
        line = line.strip()
        
        #//////////// EMOJI CATEGORY //////
        if line.startswith("# group:"):
            current_category = line.split("# group:")[1].strip().lower()
            current_category = current_category.replace(" ", "_")
            for i in range(len(current_category)):
                if current_category[i].startswith("&"):
                    current_category = current_category.replace("&", "and")
                    
        #//////////// EMOJI SUBCATEGORY //////
        elif line.startswith("# subgroup:"):
            current_subcategory = line.split("# subgroup:")[1].strip().lower()
            current_subcategory = current_subcategory.replace("-", "_")
        
        #//////////// EMOJI CODEPOINTS //////
        elif line.startswith(("0", "1", "2", "3", "4")):
            line_parts = line.split(";")
            current_codepoints = line_parts[0].strip()
            current_codepoints = f"{current_codepoints.split(' ')}"
            line_data = line_parts[1].strip().split(" ")

            #//////////// EMOJI STATUS //////
            current_status = line_data[0].strip().replace("-", "_")            
            emj_name = ""
            for item in line_data:
                
                #//////////// EMOJI //////
                if is_emoji(item):
                    current_emoji = item
                    
                #//////////// EMOJI VERSION //////
                elif item.startswith("E") and item[1].isdigit():
                    item_parts = item.strip().split("E")
                    for part in item_parts:
                        if part == "":
                            continue
                        if part[0].isdigit():
                            current_version = part
                elif item == "component" or item == "fully-qualified" or item == "minimally-qualified" or item == "unqualified":
                    continue
                elif item == '' or item == "#":
                    continue
                #//////////// EMOJI NAME //////
                # elif item == "keycap:":
                #     emj_name += item.replace(":", " ").strip()
                # elif item == "(blood":
                #     item = item.lstrip("(")
                #     new_txt = ""
                #     new_txt += "_"
                #     for i in range(len(item)):
                #         new_txt += item[i]
                #     new_txt += "_"
                #     item = new_txt
                #     emj_name += item
                # elif item == "type)":
                #     emj_name += item.rstrip(")")
                # elif item.startswith("(") and item.endswith(")"):
                #     emj_name += item.lstrip("(").rstrip(")")
                #     print(real_index, item)
                # elif ":" in item:
                #     emj_name += item.replace(":", "_")
                # elif "‚Äú" in item or "‚Äù" in item:
                #     emj_name += item.replace("‚Äú", "_").replace("‚Äù", "_")
                # else:
                #     emj_name += f"_{item}"

            #current_emoji_name = emj_name.replace("-", "_")
            
            if current_emoji in LEGACY_EMOJI_DATA:
                current_emoji_name = LEGACY_EMOJI_DATA[current_emoji]["en"]
                
            if current_emoji_name.startswith("_"):
                current_emoji_name = current_emoji_name.lstrip("_")     
            current_emoji_name = adapt_emoji_name(current_emoji_name, "en", current_emoji)
           
        #////// FILTERS //////

        # Filter out the file header text
        if current_line < 35: # Table data starts on line #35.
            continue

        real_index = real_index + 1
            
        if current_emoji is not None: 
            
            #//////////// ALIASES //////
            if current_emoji in LEGACY_EMOJI_DATA:
                if "alias" in LEGACY_EMOJI_DATA[current_emoji]:
                    current_emoji_alias = []
                    for i in range(len(LEGACY_EMOJI_DATA[current_emoji]["alias"])):
                        current_emoji_alias.append(LEGACY_EMOJI_DATA[current_emoji]["alias"][i].lower())

            #//////////// VARIANT //////
            if current_emoji in LEGACY_EMOJI_DATA:
                if "variant" in LEGACY_EMOJI_DATA[current_emoji]:
                    is_emoji_variant = LEGACY_EMOJI_DATA[current_emoji]["variant"]
                else:
                    is_emoji_variant = False
                    
            #//////////// LANGUAGES //////
            LANG_STRING = ""
            for lang in LANGUAGES:
                emoji_in_langs = _translate_emoji_name(lang)
                if current_emoji in emoji_in_langs:
                    emoji_name_in_lang = (emoji_in_langs[current_emoji])
                    if lang == "zh":
                        LANG_STRING += f"""        "{lang}": "{emoji_name_in_lang.lower()}" """
                        continue
                    LANG_STRING += f"""        "{lang}": "{emoji_name_in_lang.lower()}",\n"""

            #//////////// SEQUENCES //////
            emoji_sequence = _escape_sequence(current_emoji)
            sequence_string = ""
            for sequence in emoji_sequence.strip().split(" "):
                sequence_string += sequence
            emoji_sequence = sequence_string
            sequences = emoji_sequence.split("\\")
            escaped_sequences = []
            _new_str = ""
            for item in sequences:
                if item == '':
                    continue
                _new_str += f"\\{item}"
                escaped_sequences.append(_new_str)
                _new_str = ""
                
            #//////////// CATEGORY ID //////
            for key in CATEGORIES.keys():
                if key == current_category:
                    current_category_id = CATEGORIES[key]["id"]
                    for subkey in CATEGORIES[key].keys():
                        if subkey == current_subcategory:
                            current_subcategory_id = CATEGORIES[key][subkey]

            DATA = f"""    "{emoji_sequence}": {{  # {current_emoji}
        "index": {int(real_index)},
        "category": "{current_category}",
        "category_id": {current_category_id},
        "subcategory": "{current_subcategory}",
        "subcategory_id": {current_subcategory_id},
        "status": {current_status},
        "emoji": "{current_emoji}",
        "E": {float(current_version)},
        "unicode": {_unicode(current_emoji)},
        "codepoints": {current_codepoints},
        "sequences": {escaped_sequences},
        "variant": {is_emoji_variant},
        "alias": {current_emoji_alias},
        "name": "{current_emoji_name}",
{LANG_STRING}
    }},\n"""

            yield [DATA, [real_index, current_category, current_subcategory, current_status,
                            current_emoji, current_version, current_emoji_name,
                            _unicode(current_emoji), current_codepoints.split(" "),
                            emoji_sequence.split(" ")]]

def compile_data_dict():
    emoji_test_file = os.path.join(os.path.dirname(os.path.realpath(__file__)), "emoji_data")
    emoji_test_file = os.path.join(emoji_test_file, "emoji-v15-data")
    emoji_test_file = os.path.join(emoji_test_file, "emoji-test.txt")
    output_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), "emoji_data")
    output_path = os.path.join(output_path, "data_dict.py")

    _create_data_file(output_path)

    _write_data(
"""
\"\"\"
emoji-v15-data-dict.py

!!! ‚ö†Ô∏è DO NOT EDIT THIS FILE ‚ö†Ô∏è !!!
Don't edit this file or things will üí• and this module will be üí§üí§üí§ ...
unless you know what you're doing! This file is used by other parts of the 
module and you may and probably will encounter errors when trying to update 
or regenerate it later. You wil also encounter errors with the modules
core functions.

This file is automatically generated by running emoji_data_compiler.py
It builds on the original EMOJI_DATA dict which can be found in the 
emoji module http://github.com/carpedm20/emoji and contains a dictionary 
holding all current emoji data and properties.

This data was extracted from the following files which can be found on 
Unicode.org at:
  üîπhttps://unicode.org/Public/emoji/latest/emoji-test.txt
  üîπhttps://www.unicode.org/Public/UCD/latest/ucd/emoji/emoji-variation-sequences.txt

The emoji-test.txt file 
https://unicode.org/Public/emoji/latest/emoji-test.txt or you can run 
the download_emoji_test_data function in utils/download_emoji_data.py to
download the latest files. 

Once you download the latest data from Unicode.org you can run 
emoji_data_comiler.py to recompile this file and regenerate the EMOJIS dict
with updated information.
                          
Emoji Version Info: http://www.unicode.org/reports/tr51/#Versioning
 +----------------+-------------+------------------+-------------------+
 | Emoji Version  |    Date     | Unicode Version  | Data File Comment |
 +----------------+-------------+------------------+-------------------+
 | N/A            | 2010-10-11  | Unicode 6.0      | E0.6              |
 | N/A            | 2014-06-16  | Unicode 7.0      | E0.7              |
 | Emoji 1.0      | 2015-06-09  | Unicode 8.0      | E1.0              |
 | Emoji 2.0      | 2015-11-12  | Unicode 8.0      | E2.0              |
 | Emoji 3.0      | 2016-06-03  | Unicode 9.0      | E3.0              |
 | Emoji 4.0      | 2016-11-22  | Unicode 9.0      | E4.0              |
 | Emoji 5.0      | 2017-06-20  | Unicode 10.0     | E5.0              |
 | Emoji 11.0     | 2018-05-21  | Unicode 11.0     | E11.0             |
 | Emoji 12.0     | 2019-03-05  | Unicode 12.0     | E12.0             |
 | Emoji 12.1     | 2019-10-21  | Unicode 12.1     | E12.1             |
 | Emoji 13.0     | 2020-03-10  | Unicode 13.0     | E13.0             |
 | Emoji 13.1     | 2020-09-15  | Unicode 13.0     | E13.1             |
 | Emoji 14.0     | 2021-09-14  | Unicode 14.0     | E14.0             |
 | Emoji 15.0     | 2022-09-13  | Unicode 15.0     | E15.0 <-- current |
#  +---------------------------------------------------------------------+

Emoji versions refer to the different iterations of the Unicode Standard, 
each of which introduces new emojis, updates to existing ones, and sometimes 
changes in design or representation. These updates basically ensure that 
emojis stay relevant to the ever evolving communication trends and cultural 
contexts.

New emoji versions are typically released annually, and each version is 
associated with a specific Unicode version number. Emoji version numbers do 
not always match the Unicode version numbers exactly; they might be slightly 
different due to the release schedules and updates. 

Heres a few examples of some big updates from over the past 10 years or so
that I could find:

    üîπUnicode 6.0  (2010) introduced emoji symbols like üòÄ, üåç, üçï.
    üîπUnicode 8.0  (2015) brought in diverse skin tones for certain emojis.
    üîπUnicode 11.0 (2018) added emojis such as ü¶Ñ, üßú‚Äç‚ôÄÔ∏è, üß∏.
    üîπUnicode 13.0 (2020) included emojis like ü•≤, ü§å, ü™ê.
    
As time goes on, new emoji versions will continue to be released to keep up 
with the evolving ways people communicate and express themselves. It's important 
to note that while Unicode defines the characters and their meanings, how these 
emojis are displayed can vary depending on the operating system, device, or 
platform you're using. Different platforms might have their own interpretations 
of specific emoji designs, even though they share the same underlying Unicode code 
points.
    
\"\"\"

__all__ = [
    'STATUS' , 'LANGUAGES', 'EMOJI_DATA', 'BASIC_EMOJIS'
]             

component = 1
fully_qualified = 2
minimally_qualified = 3
unqualified = 4

STATUS = {
    "component": component,
    "fully_qualified": fully_qualified,
    "minimally_qualified": minimally_qualified,
    "unqualified": unqualified
}

LANGUAGES = ['en', 'es', 'ja', 'ko', 'pt', 'it', 'fr', 'de', 'fa', 'id', 'zh']

BASIC_EMOJIS = {
    "smileys": {
        "smiling_and_affectionate": [
        'üòÄ', 'üòÉ', 'üòÑ', 'üòÅ', 'üòÜ', 'üòÖ', 'ü§£', 'üòÇ', 'üôÇ', 'üòâ', 
        'üòä', 'üòá', 'ü•∞', 'üòç', 'ü§©', 'üòò', 'üòó', 'üòö', 'üòô', 'ü•≤', 
        'üòè'
        ],
        "tongues_hands_and_accessories": [
        'üòã', 'üòõ', 'üòú', 'ü§™', 'üòù', 'ü§ó', 'ü§≠', 'ü´¢', 'ü´£', 'ü§´',
        'ü§î', 'ü´°', 'ü§§', 'ü§†', 'ü•≥', 'ü•∏', 'üòé', 'ü§ì', 'üßê'
        ],
        "neutral_and_skeptical": [
        'üôÉ', 'ü´†', 'ü§ê', 'ü§®', 'üòê', 'üòë', 'üò∂', 'ü´•', 'üò∂‚Äçüå´Ô∏è', 'üòí',
        'üôÑ', 'üò¨', 'üòÆ‚Äçüí®', 'ü§•'
        ],
        "sleepy_and_unwell": [
        'üòå', 'üòî', 'üò™', 'üò¥', 'üò∑', 'ü§í', 'ü§ï', 'ü§¢', 'ü§Æ', 'ü§ß',
        'ü•µ', 'ü•∂', 'ü•¥', 'üòµ', 'üòµ‚Äçüí´', 'ü§Ø', 'ü•±'
        ],
        "concerned_and_negative": [
        'üòï', 'ü´§', 'üòü', 'üôÅ', '‚òπÔ∏è', 'üòÆ', 'üòØ', 'üò≤', 'üò≥', 'ü•∫',
        'ü•π', 'üò¶', 'üòß', 'üò®', 'üò∞', 'üò•', 'üò¢', 'üò≠', 'üò±', 'üòñ',
        'üò£', 'üòû', 'üòì', 'üò©', 'üò´', 'üò§', 'üò°', 'üò†', 'ü§¨', 'üëø'
        ],
        "costume_creature_and_animal": [
        'üòà', 'üëø', 'üíÄ', '‚ò†Ô∏è', 'üí©', 'ü§°', 'üëπ', 'üë∫', 'üëª', 'üëΩ', 
        'üëæ', 'ü§ñ', 'üò∫', 'üò∏', 'üòπ', 'üòª', 'üòº', 'üòΩ', 'üôÄ', 'üòø',
        'üòæ', 'üôà', 'üôâ', 'üôä'
        ]
    },
    "people": {
        "hands_and_body_parts": [
            'üëã', 'ü§ö', 'üñêÔ∏è', '‚úã', 'üññ', 'ü´±', 'ü´≤', 'ü´≥', 'ü´¥', 'üëå',
            'ü§å', 'ü§è', '‚úåÔ∏è', 'ü§û', 'ü´∞', 'ü§ü', 'ü§ò', 'ü§ô', 'üëà', 'üëâ',
            'üëÜ', 'üñï', 'üëá', '‚òùÔ∏è', 'ü´µ', 'üëç', 'üëé', '‚úä', 'üëä', 'ü§õ',
            'ü§ú', 'üëè', 'üôå', 'ü´∂', 'üëê', 'ü§≤', 'ü§ù', 'üôè', '‚úçÔ∏è', 'üíÖ',
            'ü§≥', 'üí™', 'ü¶æ', 'ü¶ø', 'ü¶µ', 'ü¶∂', 'üëÇ', 'ü¶ª', 'üëÉ', 'üß†',
            'ü´Ä', 'ü´Å', 'ü¶∑', 'ü¶¥', 'üëÄ', 'üëÖ', 'üëÑ', 'ü´¶', 'üë£', 'üß¨', 
            'ü©∏'
        ],
        "people_and_appearance": [
            'üë∂', 'üßí', 'üë¶', 'üëß', 'üßë', 'üë±', 'üë®', 'üßî', 'üßî‚Äç‚ôÇÔ∏è', 'üßî‚Äç‚ôÄÔ∏è',
            'üë®‚Äçü¶∞', 'üë®‚Äçü¶±', 'üë®‚Äçü¶≥', 'üë®‚Äçü¶≤', 'üë©', 'üë©‚Äçü¶∞', 'üßë‚Äçü¶∞', 'üë©‚Äçü¶±', 'üßë‚Äçü¶±', 'üë©‚Äçü¶≥',
            'üßë‚Äçü¶≥', 'üë©‚Äçü¶≤', 'üßë‚Äçü¶≤', 'üë±‚Äç‚ôÄÔ∏è', 'üë±‚Äç‚ôÇÔ∏è', 'üßì', 'üë¥', 'üëµ', 'üßè', 'üßè‚Äç‚ôÇÔ∏è',
            'üßè‚Äç‚ôÄÔ∏è', 'üë≥', 'üë≥‚Äç‚ôÇÔ∏è', 'üë≥‚Äç‚ôÄÔ∏è', 'üë≤', 'üßï', 'ü§∞', 'ü´É', 'ü´Ñ', 'üëº',
            'üó£Ô∏è', 'üë§', 'üë•', 'ü¶∞', 'ü¶±', 'ü¶≥', 'ü¶≤'
        ],
        "gestures_and_expressions": [
            'üôç‚Äç‚ôÇÔ∏è', 'üôç‚Äç‚ôÄÔ∏è', 'üôé', 'üôé‚Äç‚ôÇÔ∏è', 'üôé‚Äç‚ôÄÔ∏è', 'üôÖ', 'üôÖ‚Äç‚ôÇÔ∏è', 'üôÖ‚Äç‚ôÄÔ∏è', 'üôÜ', 'üôÜ‚Äç‚ôÇÔ∏è',
            'üôÜ‚Äç‚ôÄÔ∏è', 'üíÅ', 'üíÅ‚Äç‚ôÇÔ∏è', 'üíÅ‚Äç‚ôÄÔ∏è', 'üôã', 'üôã‚Äç‚ôÇÔ∏è', 'üôã‚Äç‚ôÄÔ∏è', 'üßè', 'üßè‚Äç‚ôÇÔ∏è', 'üßè‚Äç‚ôÄÔ∏è',
            'üôá', 'üôá‚Äç‚ôÇÔ∏è', 'üôá‚Äç‚ôÄÔ∏è', 'ü§¶', 'ü§¶‚Äç‚ôÇÔ∏è', 'ü§¶‚Äç‚ôÄÔ∏è', 'ü§∑', 'ü§∑‚Äç‚ôÇÔ∏è', 'ü§∑‚Äç‚ôÄÔ∏è'
        ],
        "activities_and_sports": [
            'ü§±', 'üë©‚Äçüçº', 'üßë‚Äçüçº', 'üíÜ', 'üíÜ‚Äç‚ôÇÔ∏è', 'üíÜ‚Äç‚ôÄÔ∏è', 'üíá', 'üíá‚Äç‚ôÇÔ∏è', 'üíá‚Äç‚ôÄÔ∏è', 'üö∂',
            'üö∂‚Äç‚ôÇÔ∏è', 'üö∂‚Äç‚ôÄÔ∏è', 'üßç', 'üßç‚Äç‚ôÇÔ∏è', 'üßç‚Äç‚ôÄÔ∏è', 'üßé', 'üßé‚Äç‚ôÇÔ∏è', 'üßé‚Äç‚ôÄÔ∏è', 'üßë‚Äçü¶Ø', 'üë®‚Äçü¶Ø',
            'üë©‚Äçü¶Ø', 'üßë‚Äçü¶º', 'üë®‚Äçü¶º', 'üë©‚Äçü¶º', 'üßë‚Äçü¶Ω', 'üë®‚Äçü¶Ω', 'üë©‚Äçü¶Ω', 'üèÉ', 'üèÉ‚Äç‚ôÇÔ∏è', 'üèÉ‚Äç‚ôÄÔ∏è',
            'üíÉ', 'üï∫', 'üï¥Ô∏è', 'üëØ', 'üëØ‚Äç‚ôÇÔ∏è', 'üëØ‚Äç‚ôÄÔ∏è', 'üßñ', 'üßñ‚Äç‚ôÇÔ∏è', 'üßñ‚Äç‚ôÄÔ∏è', 'üßó',
            'üßó‚Äç‚ôÇÔ∏è', 'üßó‚Äç‚ôÄÔ∏è', 'ü§∫', 'üèá', '‚õ∑Ô∏è', 'üèÇ', 'üèåÔ∏è', 'üèåÔ∏è‚Äç‚ôÇÔ∏è', 'üèåÔ∏è‚Äç‚ôÄÔ∏è', 'üèÑ',
            'üèÑ‚Äç‚ôÇÔ∏è', 'üèÑ‚Äç‚ôÄÔ∏è', 'üö£', 'üö£‚Äç‚ôÇÔ∏è', 'üö£‚Äç‚ôÄÔ∏è', 'üèä', 'üèä‚Äç‚ôÇÔ∏è', 'üèä‚Äç‚ôÄÔ∏è', '‚õπÔ∏è', '‚õπÔ∏è‚Äç‚ôÇÔ∏è',
            '‚õπÔ∏è‚Äç‚ôÄÔ∏è', 'üèãÔ∏è', 'üèãÔ∏è‚Äç‚ôÇÔ∏è', 'üèãÔ∏è‚Äç‚ôÄÔ∏è', 'üö¥', 'üö¥‚Äç‚ôÇÔ∏è', 'üö¥‚Äç‚ôÄÔ∏è', 'üöµ', 'üöµ‚Äç‚ôÇÔ∏è', 'üöµ‚Äç‚ôÄÔ∏è',
            'ü§∏', 'ü§∏‚Äç‚ôÇÔ∏è', 'ü§∏‚Äç‚ôÄÔ∏è', 'ü§º', 'ü§º‚Äç‚ôÇÔ∏è', 'ü§º‚Äç‚ôÄÔ∏è', 'ü§Ω', 'ü§Ω‚Äç‚ôÇÔ∏è', 'ü§Ω‚Äç‚ôÄÔ∏è', 'ü§æ',
            'ü§æ‚Äç‚ôÇÔ∏è', 'ü§æ‚Äç‚ôÄÔ∏è', 'ü§π', 'ü§π‚Äç‚ôÇÔ∏è', 'ü§π‚Äç‚ôÄÔ∏è', 'üßò', 'üßò‚Äç‚ôÇÔ∏è', 'üßò‚Äç‚ôÄÔ∏è', 'üõÄ', 'üõå'   
        ],
        "professions_roles_and_fantasies": [
            'üßë‚Äç‚öïÔ∏è', 'üë®‚Äç‚öïÔ∏è', 'üë©‚Äç‚öïÔ∏è', 'üßë‚Äçüéì', 'üë®‚Äçüéì', 'üë©‚Äçüéì', 'üßë‚Äçüè´', 'üë®‚Äçüè´', 'üë©‚Äçüè´', 'üßë‚Äç‚öñÔ∏è',
            'üë®‚Äç‚öñÔ∏è', 'üë©‚Äç‚öñÔ∏è', 'üßë‚Äçüåæ', 'üë®‚Äçüåæ', 'üë©‚Äçüåæ', 'üßë‚Äçüç≥', 'üë®‚Äçüç≥', 'üë©‚Äçüç≥', 'üßë‚Äçüîß', 'üë®‚Äçüîß',
            'üë©‚Äçüîß', 'üßë‚Äçüè≠', 'üë®‚Äçüè≠', 'üë©‚Äçüè≠', 'üßë‚Äçüíº', 'üë®‚Äçüíº', 'üë©‚Äçüíº', 'üßë‚Äçüî¨', 'üë®‚Äçüî¨', 'üë©‚Äçüî¨',
            'üßë‚Äçüíª', 'üë®‚Äçüíª', 'üë©‚Äçüíª', 'üßë‚Äçüé§', 'üë®‚Äçüé§', 'üë©‚Äçüé§', 'üßë‚Äçüé®', 'üë®‚Äçüé®', 'üë©‚Äçüé®', 'üßë‚Äç‚úàÔ∏è',
            'üë®‚Äç‚úàÔ∏è', 'üßë‚ÄçüöÄ', 'üë®‚ÄçüöÄ', 'üë©‚ÄçüöÄ', 'üßë‚Äçüöí', 'üë®‚Äçüöí', 'üë©‚Äçüöí', 'üëÆ', 'üëÆ‚Äç‚ôÇÔ∏è', 'üëÆ‚Äç‚ôÄÔ∏è',
            'üïµÔ∏è', 'üïµÔ∏è‚Äç‚ôÇÔ∏è', 'üïµÔ∏è‚Äç‚ôÄÔ∏è', 'üíÇ', 'üíÇ‚Äç‚ôÇÔ∏è', 'üíÇ‚Äç‚ôÄÔ∏è', 'ü•∑', 'üë∑', 'üë∑‚Äç‚ôÇÔ∏è', 'üë∑‚Äç‚ôÄÔ∏è',
            'ü´Ö', 'ü§¥', 'üë∏', 'ü§µ', 'ü§µ‚Äç‚ôÇÔ∏è', 'ü§µ‚Äç‚ôÄÔ∏è', 'üë∞', 'üë∞‚Äç‚ôÇÔ∏è', 'üë∞‚Äç‚ôÄÔ∏è', 'üéÖ',
            'ü§∂', 'üßë‚ÄçüéÑ', 'ü¶∏', 'ü¶∏‚Äç‚ôÇÔ∏è', 'ü¶∏‚Äç‚ôÄÔ∏è', 'ü¶π', 'ü¶π‚Äç‚ôÇÔ∏è', 'ü¶π‚Äç‚ôÄÔ∏è', 'üßô', 'üßô‚Äç‚ôÇÔ∏è',
            'üßô‚Äç‚ôÄÔ∏è', 'üßö', 'üßö‚Äç‚ôÇÔ∏è', 'üßö‚Äç‚ôÄÔ∏è', 'üßõ', 'üßõ‚Äç‚ôÇÔ∏è', 'üßõ‚Äç‚ôÄÔ∏è', 'üßú', 'üßú‚Äç‚ôÇÔ∏è', 'üßú‚Äç‚ôÄÔ∏è',
            'üßù', 'üßù‚Äç‚ôÇÔ∏è', 'üßù‚Äç‚ôÄÔ∏è', 'üßû', 'üßû‚Äç‚ôÇÔ∏è', 'üßû‚Äç‚ôÄÔ∏è', 'üßü', 'üßü‚Äç‚ôÇÔ∏è', 'üßü‚Äç‚ôÄÔ∏è', 'üßå',
            'üëØ', 'üëØ‚Äç‚ôÇÔ∏è', 'üëØ‚Äç‚ôÄÔ∏è'
        ],
        "families_couples": [
            'üßë‚Äçü§ù‚Äçüßë', 'üë≠', 'üë´', 'üë¨', 'üíè',
            'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®', 'üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®', 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©', 'üíë', 'üë©‚Äç‚ù§Ô∏è‚Äçüë®',
            'üë®‚Äç‚ù§Ô∏è‚Äçüë®', 'üë©‚Äç‚ù§Ô∏è‚Äçüë©', 'üë™', 'üë®‚Äçüë©‚Äçüë¶', 'üë®‚Äçüë©‚Äçüëß',
            'üë®‚Äçüë©‚Äçüëß‚Äçüë¶', 'üë®‚Äçüë©‚Äçüë¶‚Äçüë¶', 'üë®‚Äçüë©‚Äçüëß‚Äçüëß', 'üë®‚Äçüë®‚Äçüë¶', 'üë®‚Äçüë®‚Äçüëß',
            'üë®‚Äçüë®‚Äçüëß‚Äçüë¶', 'üë®‚Äçüë®‚Äçüë¶‚Äçüë¶', 'üë®‚Äçüë®‚Äçüëß‚Äçüëß', 'üë©‚Äçüë©‚Äçüë¶', 'üë©‚Äçüë©‚Äçüëß',
            'üë©‚Äçüë©‚Äçüëß‚Äçüë¶', 'üë©‚Äçüë©‚Äçüë¶‚Äçüë¶', 'üë©‚Äçüë©‚Äçüëß‚Äçüëß', 'üë®‚Äçüë¶', 'üë®‚Äçüë¶‚Äçüë¶',
            'üë®‚Äçüëß', 'üë®‚Äçüëß‚Äçüë¶', 'üë®‚Äçüëß‚Äçüëß', 'üë©‚Äçüë¶', 'üë©‚Äçüë¶‚Äçüë¶', 'üë©‚Äçüëß',
            'üë©‚Äçüëß‚Äçüë¶', 'üë©‚Äçüëß‚Äçüëß', 'üë©‚Äçüë®‚Äçüëß‚Äçüëß', 'üë©‚Äçüë¶‚Äçüëß', 'üë©‚Äçüë®‚Äçüë¶‚Äçüë¶',
            'üë®‚Äçüë®‚Äçüë¶‚Äçüëß', 'üë©‚Äçüë®‚Äçüëß‚Äçüë¶', 'üë®‚Äçüë¶‚Äçüëß', 'üë©‚Äçüë®‚Äçüë¶', 'üë©‚Äçüë©‚Äçüë¶‚Äçüëß',
            'üë©‚Äçüë®‚Äçüë¶‚Äçüëß', 'üë©‚Äçüë®‚Äçüëß', 'üë®‚Äçüë©‚Äçüë¶‚Äçüëß'
        ]
    },
    "animals_and_nature": {
        "mammals_and_marsupials": [
            'üêµ', 'üêí', 'ü¶ç', 'ü¶ß', 'üê∂', 'üêï', 'ü¶Æ', 'üêï‚Äçü¶∫', 'üê©', 'üê∫',
            'ü¶ä', 'ü¶ù', 'üê±', 'üêà', 'üêà‚Äç‚¨õ', 'ü¶Å', 'üêØ', 'üêÖ', 'üêÜ', 'üê¥',
            'üêé', 'ü¶Ñ', 'ü¶ì', 'ü¶å', 'ü¶¨', 'üêÆ', 'üêÇ', 'üêÉ', 'üêÑ', 'üê∑', 
            'üêñ', 'üêó', 'üêΩ', 'üêè', 'üêë', 'üêê', 'üê™', 'üê´', 'ü¶ô', 'ü¶í', 
            'üêò', 'ü¶£', 'ü¶è', 'ü¶õ', 'üê≠', 'üêÅ', 'üêÄ', 'üêπ', 'üê∞', 'üêá', 
            'üêøÔ∏è', 'ü¶´', 'ü¶î', 'ü¶á', 'üêª', 'üêª‚Äç‚ùÑÔ∏è', 'üê®', 'üêº', 'ü¶•', 'ü¶¶', 
            'ü¶®', 'ü¶ò', 'ü¶°', 'üêæ'
        ],
        "birds": [
            'ü¶É', 'üêî', 'üêì', 'üê£', 'üê§', 'üê•', 'üê¶', 'üê¶', 'üêß', 'üïäÔ∏è',
            'ü¶Ö', 'ü¶Ü', 'ü¶¢', 'ü¶â', 'ü¶§', 'ü™∂', 'ü¶©', 'ü¶ö', 'ü¶ú', 'ü™π', 
            'ü™∫'
        ],
        "marine_and_reptiles": [
            'üê∏', 'üêä', 'üê¢', 'ü¶é', 'üêç', 'üê≤', 'üêâ', 'ü¶ï', 'ü¶ñ', 'üê≥',
            'üêã', 'üê¨', 'ü¶≠', 'üêü', 'üê†', 'üê°', 'ü¶à', 'üêô', 'üêö', 'ü™∏', 
            'ü¶Ä', 'ü¶û', 'ü¶ê', 'ü¶ë', 'ü¶™'
        ],
        "bugs": [
            'üêå', 'ü¶ã', 'üêõ', 'üêú', 'üêù', 'ü™≤', 'üêû', 'ü¶ó', 'ü™≥', 'üï∑Ô∏è',
            'üï∏Ô∏è', 'ü¶Ç', 'ü¶ü', 'ü™∞', 'ü™±', 'ü¶†'
        ],
        "plants_flowers_and_nature": [
            'üíê', 'üå∏', 'üíÆ', 'ü™∑', 'üèµÔ∏è', 'üåπ', 'ü•Ä', 'üå∫', 'üåª', 'üåº', 
            'üå∑', 'üå±', 'ü™¥', 'üå≤', 'üå≥', 'üå¥', 'üåµ', 'üåæ', 'üåø', '‚òòÔ∏è', 
            'üçÄ', 'üçÅ', 'üçÇ', 'üçÉ', 'üçÑ', 'ü™®', 'ü™µ'
        ],
        "sky_and_weather": [
            '‚ù§Ô∏è‚Äçüî•', 'üåë', 'üåí', 'üåì', 'üåî', 'üåï', 'üåñ', 'üåó', 'üåò', 'üåô',
            'üåö', 'üåõ', 'üåú', '‚òÄÔ∏è', 'üåù', 'üåû', 'ü™ê', '‚≠ê', 'üåü', 'üå†',
            'üåå', '‚òÅÔ∏è', '‚õÖ', '‚õàÔ∏è', 'üå§Ô∏è', 'üå•Ô∏è', 'üå¶Ô∏è', 'üåßÔ∏è', 'üå®Ô∏è', 'üå©Ô∏è',
            'üå™Ô∏è', 'üå´Ô∏è', 'üå¨Ô∏è', 'üåÄ', 'üåà', 'üåÇ', '‚òÇÔ∏è', '‚òî', '‚õ±Ô∏è', '‚ö°',
            '‚ùÑÔ∏è', '‚òÉÔ∏è', '‚õÑ', '‚òÑÔ∏è', 'üíß', 'üåä' 
        ]
    },
    "food_and_drink": {
        "fruits": [
            'üçá', 'üçà', 'üçâ', 'üçä', 'üçã', 'üçå', 'üçç', 'ü•≠', 'üçé', 'üçè',
            'üçê', 'üçë', 'üçí', 'üçì', 'ü´ê', 'ü•ù', 'üçÖ', 'ü´í', 'ü••'
        ],
        "vegetables": [
            'ü•ë', 'üçÜ', 'ü•î', 'ü•ï', 'üåΩ', 'üå∂Ô∏è', 'ü´ë', 'ü•í', 'ü•¨', 'ü•¶', 
            'üßÑ', 'üßÖ', 'ü•ú', 'ü´ò', 'üå∞'
        ],
        "prepared_foods": [
            'üçû', 'ü•ê', 'ü•ñ', 'ü´ì', 'ü•®', 'ü•Ø', 'ü•û', 'üßá', 'üßÄ', 'üçñ',
            'üçó', 'ü•©', 'ü•ì', 'üçî', 'üçü', 'üçï', 'üå≠', 'ü•™', 'üåÆ', 'üåØ',
            'ü´î', 'ü•ô', 'üßÜ', 'ü•ö', 'üç≥', 'ü•ò', 'üç≤', 'ü´ï', 'ü•£', 'ü•ó',
            'üçø', 'üßà', 'üßÇ', 'ü•´', 'üçù'
        ],
        "asian_foods": [
            'üç±', 'üçò', 'üçô', 'üçö', 'üçõ', 'üçú', 'üç†', 'üç¢', 'üç£', 'üç§',
            'üç•', 'ü•Æ', 'üç°', 'ü•ü', 'ü•†', 'ü•°'
        ],
        "sweets_and_deserts": [
            'üç¶', 'üçß', 'üç®', 'üç©', 'üç™', 'üéÇ', 'üç∞', 'üßÅ', 'ü•ß', 'üç´',
            'üç¨', 'üç≠', 'üçÆ', 'üçØ'
        ],
        "drinks_and_dishware": [
            'üçº', 'ü•õ', '‚òï', 'ü´ñ', 'üçµ', 'üç∂', 'üçæ', 'üç∑', 'üç∏', 'üçπ',
            'üç∫', 'üçª', 'ü•Ç', 'ü•É', 'ü´ó', 'ü•§', 'üßã', 'üßÉ', 'üßâ', 'ü•¢', 
            'üçΩÔ∏è', 'üç¥', 'ü•Ñ', 'üî™', 'ü´ô', 'üè∫'
        ]
    },
    "activity": {
        "events_and_celebration": [
            'üéÉ', 'üéÑ', 'üéÜ', 'üéá', 'üß®', '‚ú®', 'üéà', 'üéâ', 'üéä', 'üéã',
            'üéç', 'üéé', 'üéè', 'üéê', 'üéë', 'üßß', 'üéÅ', 'üéüÔ∏è', 'üé´', 'üèÆ',
            'ü™î'
        ],
        "sports_and_awards": [
            'üéñÔ∏è', 'üèÜ', 'üèÖ', 'ü•á', 'ü•à', 'ü•â', '‚öΩ', '‚öæ', 'ü•é', 'üèÄ',
            'üèê', 'üèà', 'üèâ', 'üéæ', 'ü•è', 'üé≥', 'üèè', 'üèë', 'üèí', 'ü•ç',
            'üèì', 'üè∏', 'ü•ä', 'ü•ã', 'ü•Ö', '‚õ≥', '‚õ∏Ô∏è', 'üé£', 'ü§ø', 'üéΩ',
            'üéø', 'üõ∑', 'ü•å', 'üéØ'
        ],
        "games_and_culture": [
            'ü™Ä', 'ü™Å', 'üé±', 'üîÆ', 'ü™Ñ', 'üéÆ', 'üïπÔ∏è', 'üé∞', 'üé≤', 'üß©',
            'ü™Ö', 'ü™©', 'ü™Ü', '‚ô†Ô∏è', '‚ô•Ô∏è', '‚ô¶Ô∏è', '‚ô£Ô∏è', '‚ôüÔ∏è', 'üÉè', 'üÄÑ', 'üé¥', 
            'üé≠', 'üñºÔ∏è', 'üé®', 'üî´'
        ]
    },
    "travel_and_places": {
        "maps_and_geography": [
            'üåç', 'üåé', 'üåè', 'üåê', 'üó∫Ô∏è', 'üóæ', 'üß≠', 'üèîÔ∏è', '‚õ∞Ô∏è', 'üåã',
            'üóª', 'üèïÔ∏è', 'üèñÔ∏è', 'üèúÔ∏è', 'üèùÔ∏è', 'üèûÔ∏è'
        ],
        "buildings_and_places": [
            'üèüÔ∏è', 'üèõÔ∏è', 'üèóÔ∏è', 'üß±', 'üõñ', 'üèòÔ∏è', 'üèöÔ∏è', 'üè†', 'üè°', 'üè¢',
            'üè£', 'üè§', 'üè•', 'üè¶', 'üè®', 'üè©', 'üè™', 'üè´', 'üè¨', 'üè≠',
            'üèØ', 'üè∞', 'üíí', 'üóº', 'üóΩ', '‚õ™', 'üïå', 'üõï', 'üïç', '‚õ©Ô∏è',
            'üïã', '‚õ≤', '‚õ∫', 'üåÅ', 'üåÉ', 'üèôÔ∏è', 'üåÑ', 'üåÖ', 'üåÜ', 'üåá',
            'üåâ', '‚ô®Ô∏è', 'üé†', 'üõù', 'üé°', 'üé¢', 'üíà', 'üé™', 'üõéÔ∏è', 'üóø'
        ],
        "land_travel": [
            'üöÇ', 'üöÉ', 'üöÑ', 'üöÖ', 'üöÜ', 'üöá', 'üöà', 'üöâ', 'üöä', 'üöù',
            'üöû', 'üöã', 'üöå', 'üöç', 'üöé', 'üöê', 'üöë', 'üöí', 'üöì', 'üöî',
            'üöï', 'üöñ', 'üöó', 'üöò', 'üöô', 'üõª', 'üöö', 'üöõ', 'üöú', 'üèéÔ∏è',
            'üèçÔ∏è', 'üõµ', 'ü¶Ω', 'ü¶º', 'üõ∫', 'üö≤', 'üõ¥', 'üõπ', 'üõº', 'üöè',
            'üõ£Ô∏è', 'üõ§Ô∏è', 'üõ¢Ô∏è', '‚õΩ', 'üõû', 'üö®', 'üö•', 'üö¶', 'üõë', 'üöß'
        ],
        "air_and_sea_travel": [
            '‚öì', 'üõü', '‚õµ', 'üõ∂', 'üö§', 'üõ≥Ô∏è', '‚õ¥Ô∏è', 'üõ•Ô∏è', 'üö¢', '‚úàÔ∏è',
            'üõ©Ô∏è', 'üõ´', 'üõ¨', 'ü™Ç', 'üí∫', 'üöÅ', 'üöü', 'üö†', 'üö°', 'üõ∞Ô∏è',
            'üöÄ', 'üõ∏'
        ]
    },
    "objects": {
        "clothing_and_appearence": [
            'üéÄ', 'üéóÔ∏è', 'üëì', 'üï∂Ô∏è', 'ü•Ω', 'ü•º', 'ü¶∫', 'üëî', 'üëï', 'üëñ',
            'üß£', 'üß§', 'üß•', 'üß¶', 'üëó', 'üëò', 'ü•ª', 'ü©±', 'ü©≤', 'ü©≥',
            'üëô', 'üëö', 'üëõ', 'üëú', 'üëù', 'üõçÔ∏è', 'üéí', 'ü©¥', 'üëû', 'üëü', 
            'ü•æ', 'ü•ø', 'üë†', 'üë°', 'ü©∞', 'üë¢', 'üëë', 'üëí', 'üé©', 'üéì', 
            'üß¢', 'ü™ñ', '‚õëÔ∏è', 'üìø', 'üíÑ', 'üíç', 'üíé', 'ü¶Ø'
        ],
        "music_and_sound": [
            'üîá', 'üîà', 'üîâ', 'üîä', 'üì¢', 'üì£', 'üìØ', 'üîî', 'üîï', 'üéº',
            'üéµ', 'üé∂', 'üéôÔ∏è', 'üéöÔ∏è', 'üéõÔ∏è', 'üé§', 'üéß', 'üìª', 'üé∑', 'ü™ó',
            'üé∏', 'üéπ', 'üé∫', 'üéª', 'ü™ï', 'ü•Å', 'ü™ò'
        ],
        "it_and_av": [
            'üì±', 'üì≤', '‚òéÔ∏è', 'üìû', 'üìü', 'üì†', 'üîã', 'ü™´', 'üîå', 'üíª',
            'üñ•Ô∏è', 'üñ®Ô∏è', '‚å®Ô∏è', 'üñ±Ô∏è', 'üñ≤Ô∏è', 'üíΩ', 'üíæ', 'üíø', 'üìÄ', 'üé•',
            'üéûÔ∏è', 'üìΩÔ∏è', 'üé¨', 'üì∫', 'üì∑', 'üì∏', 'üìπ', 'üìº'
        ],
        "office_and_stationary": [
            'üìî', 'üìï', 'üìñ', 'üìó', 'üìò', 'üìô', 'üìö', 'üìì', 'üìí', 'üìÉ',
            'üìú', 'üìÑ', 'üì∞', 'üóûÔ∏è', 'üìë', 'üîñ', 'üè∑Ô∏è', '‚úâÔ∏è', 'üìß', 'üì®',
            'üì©', 'üì§', 'üì•', 'üì¶', 'üì´', 'üì™', 'üì¨', 'üì≠', 'üìÆ', 'üó≥Ô∏è',
            '‚úèÔ∏è', '‚úíÔ∏è', 'üñãÔ∏è', 'üñäÔ∏è', 'üñåÔ∏è', 'üñçÔ∏è', 'üìù', 'üíº', 'üìÅ', 'üìÇ',
            'üóÇÔ∏è', 'üìÖ', 'üìÜ', 'üóíÔ∏è', 'üóìÔ∏è', 'üìá', 'üìà', 'üìâ', 'üìä', 'üìã',
            'üìå', 'üìç', 'üìé', 'üñáÔ∏è', 'üìè', 'üìê', '‚úÇÔ∏è', 'üóÉÔ∏è', 'üóÑÔ∏è', 'üóëÔ∏è'
        ],
        "money_and_time": [
            '‚åõ', '‚è≥', '‚åö', '‚è∞', '‚è±Ô∏è', '‚è≤Ô∏è', 'üï∞Ô∏è', 'üïõ', 'üïß', 'üïê',
            'üïú', 'üïë', 'üïù', 'üïí', 'üïû', 'üïì', 'üïü', 'üïî', 'üï†', 'üïï',
            'üï°', 'üïñ', 'üï¢', 'üïó', 'üï£', 'üïò', 'üï§', 'üïô', 'üï•', 'üïö',
            'üï¶', 'üßÆ', 'üí∞', 'ü™ô', 'üí¥', 'üíµ', 'üí∂', 'üí∑', 'üí∏', 'üí≥',
            'üßæ', 'üíπ'
        ],
        "tools_and_household_items": [
            'üöÇ', 'üöÉ', 'üöÑ', 'üöÖ', 'üöÜ', 'üöá', 'üöà', 'üöâ', 'üöä', 'üöù',
            'üöû', 'üöã', 'üöå', 'üöç', 'üöé', 'üöê', 'üöë', 'üöí', 'üöì', 'üöî', 
            'üöï', 'üöñ', 'üöó', 'üöò'
        ]
    },
    "symbols": {
        "hearts_shapes_and_emotions": [
            'üíã', 'üíå', 'üíò', 'üíù', 'üíñ', 'üíó', 'üíì', 'üíû', 'üíï', 'üíü', 
            '‚ù£Ô∏è', 'üíî', '‚ù§Ô∏è‚Äçüî•', '‚ù§Ô∏è‚Äçü©π', '‚ù§Ô∏è', 'üß°', 'üíõ', 'üíö', 'üíô', 'üíú',
            'ü§é', 'üñ§', 'ü§ç', 'üíØ', 'üí¢', 'üí•', 'üí¶', 'üí®', 'üï≥Ô∏è', 'üí¨',
            'üëÅÔ∏è‚Äçüó®Ô∏è', 'üó®Ô∏è', 'üóØÔ∏è', 'üí≠', 'üí§', 'üî¥', 'üü†', 'üü°', 'üü¢', 'üîµ',
            'üü£', 'üü§', '‚ö´', '‚ö™', 'üü•', 'üüß', 'üü®', 'üü©', 'üü¶', 'üü™',
            'üü´', '‚¨ú', '‚óºÔ∏è', '‚óªÔ∏è', '‚óæ', '‚óΩ', '‚ñ™Ô∏è', '‚ñ´Ô∏è', 'üî∂', 'üî∑',
            'üî∏', 'üîπ', 'üî∫', 'üîª', 'üí†', 'üîò', 'üî≥', 'üî≤'
        ],
        "location_and_warning": [
            'üõó', 'üèß', 'üöÆ', 'üö∞', '‚ôø', 'üöπ', 'üö∫', 'üöª', 'üöº', 'üöæ',
            'üõÇ', 'üõÉ', 'üõÑ', 'üõÖ', '‚ö†Ô∏è', 'üö∏', '‚õî', 'üö´', 'üö≥', 'üö≠', 
            'üöØ', 'üö±', 'üö∑', 'üìµ', 'üîû', '‚ò¢Ô∏è', '‚ò£Ô∏è'
        ],
        "arrows_and_av": [
            '‚¨ÜÔ∏è', '‚ÜóÔ∏è', '‚û°Ô∏è', '‚ÜòÔ∏è', '‚¨áÔ∏è', '‚ÜôÔ∏è', '‚¨ÖÔ∏è', '‚ÜñÔ∏è', '‚ÜïÔ∏è', '‚ÜîÔ∏è',
            '‚Ü©Ô∏è', '‚Ü™Ô∏è', '‚§¥Ô∏è', '‚§µÔ∏è', 'üîÉ', 'üîÑ', 'üîô', 'üîö', 'üîõ', 'üîú',
            'üîù', 'üîÄ', 'üîÅ', 'üîÇ', '‚ñ∂Ô∏è', '‚è©', '‚è≠Ô∏è', '‚èØÔ∏è', '‚óÄÔ∏è', '‚è™',
            '‚èÆÔ∏è', 'üîº', '‚è´', 'üîΩ', '‚è¨', '‚è∏Ô∏è', '‚èπÔ∏è', '‚è∫Ô∏è', '‚èèÔ∏è', 'üé¶',
            'üîÖ', 'üîÜ', 'üì∂', 'üì≥', 'üì¥'   
        ],
        "identities_and_beliefs": [
            'üõê', 'üïâÔ∏è', '‚ú°Ô∏è', '‚ò∏Ô∏è', '‚òØÔ∏è', '‚úùÔ∏è', '‚ò¶Ô∏è', '‚ò™Ô∏è', '‚òÆÔ∏è', 'üïé', 
            'üîØ', '‚ôà', '‚ôâ', '‚ôä', '‚ôã', '‚ôå', '‚ôç', '‚ôé', '‚ôè', '‚ôê', 
            '‚ôë', '‚ôí', '‚ôì', '‚õé', '‚ôÄÔ∏è', '‚ôÇÔ∏è', '‚ößÔ∏è'   
        ],
        "alphanumerics": [
            '‚úñÔ∏è', '‚ûï', '‚ûñ', '‚ûó', 'üü∞', '‚ôæÔ∏è', '‚ÄºÔ∏è', '‚ÅâÔ∏è', '‚ùì', '‚ùî',
            '‚ùï', '‚ùó', '„Ä∞Ô∏è', 'üí±', 'üí≤', '#Ô∏è‚É£', '*Ô∏è‚É£', '0Ô∏è‚É£', '1Ô∏è‚É£', '2Ô∏è‚É£',
            '3Ô∏è‚É£', '4Ô∏è‚É£',  '5Ô∏è‚É£', '6Ô∏è‚É£', '7Ô∏è‚É£', '8Ô∏è‚É£', '9Ô∏è‚É£', 'üîü', 'üî†', 'üî°',
            'üî¢', 'üî£', 'üî§', 'üÖ∞Ô∏è', 'üÜé', 'üÖ±Ô∏è', 'üÜë', 'üÜí', 'üÜì', '‚ÑπÔ∏è',
            'üÜî', '‚ìÇÔ∏è', 'üÜï', 'üÜñ', 'üÖæÔ∏è', 'üÜó', 'üÜò', 'üÜô', 'üÜö', 'üàÅ',
            'üàÇÔ∏è', 'üà∑Ô∏è', 'üà∂', 'üàØ', 'üâê', 'üàπ', 'üàö', 'üà≤', 'üâë', 'üà∏',
            'üà¥', 'üà≥', '„äóÔ∏è', '„äôÔ∏è', 'üà∫', 'üàµ'
        ],
        "other_symbols": [
            '‚öïÔ∏è', '‚ôªÔ∏è', '‚öúÔ∏è', 'üìõ', 'üî∞', '‚≠ï', '‚úÖ', '‚òëÔ∏è', '‚úîÔ∏è', '‚ùå',
            '‚ùé', '‚û∞', '‚ûø', '„ÄΩÔ∏è', '‚ú≥Ô∏è', '‚ú¥Ô∏è', '‚ùáÔ∏è', '¬©Ô∏è', '¬ÆÔ∏è', '‚Ñ¢Ô∏è'
        ]
    },
    "flags": {
        "color_and_identity": [
            'üèÅ', 'üö©', 'üéå', 'üè¥', 'üè≥Ô∏è', 'üè≥Ô∏è‚Äçüåà', 'üè≥Ô∏è‚Äç‚ößÔ∏è', 'üè¥‚Äç‚ò†Ô∏è', 'üá∫üá≥'
        ],
        "africa": [
            'üá¶üá¥', 'üáßüá´', 'üáßüáÆ', 'üáßüáØ', 'üáßüáº', 'üá®üá©', 'üá®üá´', 'üá®üá¨', 'üá®üáÆ', 'üá®üá≤',
            'üá®üáª', 'üá©üáØ', 'üá©üáø', 'üá™üá¨', 'üá™üá≠', 'üá™üá∑', 'üá™üáπ', 'üá¨üá¶', 'üá¨üá≠', 'üá¨üá≤',
            'üá¨üá≥', 'üá¨üá∂', 'üá¨üáº', 'üá∞üá™', 'üá∞üá≤', 'üá±üá∑', 'üá±üá∏', 'üá±üáæ', 'üá≤üá¶', 'üá≤üá¨',
            'üá≤üá±', 'üá≤üá∑', 'üá≤üá∫', 'üá≤üáº', 'üá≤üáø', 'üá≥üá¶', 'üá≥üá™', 'üá≥üá¨', 'üá∑üáº', 'üá∏üá®',
            'üá∏üá©', 'üá∏üá±', 'üá∏üá≥', 'üá∏üá¥', 'üá∏üá∏', 'üá∏üáø', 'üáπüá©', 'üáπüá¨', 'üáπüá≥', 'üáπüáø',
            'üá∫üá¨', 'üáøüá¶', 'üáøüá≤', 'üáøüáº'
        ],
        "the_americas": [
            'üá¶üá¨', 'üá¶üáÆ', 'üá¶üá∑', 'üá¶üáº', 'üáßüáß', 'üáßüá±', 'üáßüá≤', 'üáßüá¥', 'üáßüá∂', 'üáßüá∑',
            'üáßüá∏', 'üáßüáø', 'üá®üá¶', 'üá®üá±', 'üá®üá¥', 'üá®üá∑', 'üá®üá∫', 'üá®üáº', 'üá©üá≤', 'üá©üá¥',
            'üá™üá®', 'üá´üá∞', 'üá¨üá©', 'üá¨üá´', 'üá¨üáµ', 'üá¨üáπ', 'üá¨üáæ', 'üá≠üá≥', 'üá≠üáπ', 'üáØüá≤',
            'üá∞üá≥', 'üá∞üáæ', 'üá±üá®', 'üá≤üá´', 'üá≤üá∂', 'üá≤üá∏', 'üá≤üáΩ', 'üá≥üáÆ', 'üáµüá¶', 'üáµüá™',
            'üáµüá≤', 'üáµüá∑', 'üáµüáæ', 'üá∏üá∑', 'üá∏üáª', 'üá∏üáΩ', 'üáπüá®', 'üáπüáπ', 'üá∫üá∏', 'üá∫üáæ',
            'üáªüá™', 'üáªüá¨', 'üáªüáÆ'
        ],
        "asia_and_the_middle_east": [
            'üá¶üá™', 'üá¶üá´', 'üá¶üáø', 'üáßüá©', 'üáßüá≠', 'üáßüá≥', 'üáßüáπ', 'üá®üá≥', 'üá≠üá∞', 'üáÆüá©',
            'üáÆüá±', 'üáÆüá≥', 'üáÆüá∂', 'üáÆüá∑', 'üáØüá¥', 'üáØüáµ', 'üá∞üá¨', 'üá∞üá≠', 'üá∞üáµ', 'üá∞üá∑',
            'üá∞üáº', 'üá∞üáø', 'üá±üá¶', 'üá±üáß', 'üá±üá∞', 'üá≤üá≤', 'üá≤üá≥', 'üá≤üá¥', 'üá≤üáª', 'üá≤üáæ',
            'üá≥üáµ', 'üá¥üá≤', 'üáµüá≠', 'üáµüá∞', 'üáµüá∏', 'üá∂üá¶', 'üá∑üá∫', 'üá∏üá¶', 'üá∏üá¨', 'üá∏üáæ',
            'üáπüá≠', 'üáπüáØ', 'üáπüá±', 'üáπüá≤', 'üáπüá∑', 'üáπüáº', 'üá∫üáø', 'üáªüá≥', 'üáæüá™'
        ],
        "europe": [
            'üá¶üá©', 'üá¶üá±', 'üá¶üá≤', 'üá¶üáπ', 'üáßüá¶', 'üáßüá™', 'üáßüá¨', 'üáßüáæ', 'üá®üá≠', 'üá®üáæ',
            'üá®üáø', 'üá©üá™', 'üá©üá∞', 'üá™üá¶', 'üá™üá™', 'üá™üá∏', 'üá™üá∫', 'üá´üáÆ', 'üá´üá∑', 'üá¨üáß',
            'üá¨üá™', 'üá¨üá¨', 'üá¨üáÆ', 'üá¨üá∑', 'üá≠üá∑', 'üá≠üá∫', 'üáÆüá™', 'üáÆüá≤', 'üáÆüá∏', 'üáÆüáπ',
            'üáØüá™', 'üá±üáÆ', 'üá±üáπ', 'üá±üá∫', 'üá±üáª', 'üá≤üá®', 'üá≤üá©', 'üá≤üá™', 'üá≤üá∞', 'üá≤üáπ',
            'üá≥üá±', 'üá≥üá¥', 'üáµüá±', 'üáµüáπ', 'üá∑üá¥', 'üá∑üá∏', 'üá∑üá∫', 'üá∏üá™', 'üá∏üáÆ', 'üá∏üá∞',
            'üá∏üá≤', 'üá∫üá¶', 'üáªüá¶', 'üáΩüá∞', 'üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø', 'üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø', 'üè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†Åø'
        ],
        "oceania_island_nations_and_territories": [
            'üá¶üá®', 'üá¶üá∂', 'üá¶üá∏', 'üá¶üá∫', 'üá¶üáΩ', 'üáßüáª', 'üá®üá®', 'üá®üá∞', 'üá®üáµ', 'üá®üáΩ',
            'üá©üá¨', 'üá´üáØ', 'üá´üá≤', 'üá¨üá±', 'üá¨üá∏', 'üá¨üá∫', 'üá≠üá≤', 'üáÆüá®', 'üáÆüá¥', 'üá∞üáÆ',
            'üá≤üá≠', 'üá≤üáµ', 'üá≥üá®', 'üá≥üá´', 'üá≥üá∑', 'üá≥üá∫', 'üá≥üáø', 'üáµüá´', 'üáµüá¨', 'üáµüá≥',
            'üáµüáº', 'üá∑üá™', 'üá∏üáß', 'üá∏üá≠', 'üá∏üáØ', 'üá∏üáπ', 'üáπüá¶', 'üáπüá´', 'üáπüá∞', 'üáπüá¥',
            'üáπüáª', 'üá∫üá≤', 'üáªüá®', 'üáªüá∫', 'üáºüá´', 'üáºüá∏', 'üáæüáπ'
        ]
    }
}

CATEGORIES = {
    "smileys_and_emotion": {
        'id': 491122,
        'face_smiling': 4745, 
        'face_affection': 9488, 
        'face_tongue': 14227, 
        'face_hand': 18967,
        'face_neutral_skeptical': 23715, 
        'face_sleepy': 28453,
        'face_unwell': 33198, 
        'face_hat': 37934,
        'face_glasses': 42670, 
        'face_concerned': 47430, 
        'face_negative': 52172, 
        'face_costume': 56913, 
        'cat_face': 61655,
        'monkey_face': 66391, 
        'heart': 71153, 
        'emotion': 75906
    },
    "people_and_body": {
        'id': 899911,
        'hand_fingers_open': 85439, 
        'hand_fingers_partial': 90227, 
        'hand_single_finger': 95003, 
        'hand_fingers_closed': 99772, 
        'hands': 104567, 
        'hand_prop': 109319, 
        'body_parts': 114101, 
        'person': 119026, 
        'person_gesture': 124059, 
        'person_role': 129427, 
        'person_fantasy': 134405, 
        'person_activity': 139456, 
        'person_sport': 144584, 
        'person_resting': 149359, 
        'family': 154626, 
        'person_symbol': 159365
    },
    "component": {
        'id': 113687,
        'skin_tone': 168836, 
        'hair_style': 173573
    },
    "animals_and_nature": {
        'id': 116815,
        'animal_mammal': 183107, 
        'animal_bird': 187862, 
        'animal_amphibian': 192596, 
        'animal_reptile': 197337, 
        'animal_marine': 202082, 
        'animal_bug': 206833, 
        'plant_flower': 211579, 
        'plant_other': 216329
    },
    "food_and_drink": {
        'id': 228130,
        'food_fruit': 225814, 
        'food_vegetable': 230565, 
        'food_prepared': 235332, 
        'food_asian': 240082, 
        'food_marine': 244820, 
        'food_sweet': 249567, 
        'drink': 254320, 
        'dishware': 259061
    },
    "travel_and_places": {
        'id': 227294,
        'place_map': 268535, 
        'place_geographic': 273284, 
        'place_building': 278049, 
        'place_religious': 282789, 
        'place_other': 287541, 
        'transport_ground': 292329, 
        'transport_water': 297074, 
        'transport_air': 301823, 
        'hotel': 306559, 
        'time': 311326,
        'sky_and_weather': 316124
    },
    "activities": {
        'id': 335508,
        'event': 325613, 
        'award_medal': 330353, 
        'sport': 335114, 
        'game': 339877, 
        'arts_and_crafts': 344618
    },
    "objects": {
        'id': 336837,
        'clothing': 354134, 
        'sound': 358876, 
        'music': 363621, 
        'musical_instrument': 368365, 
        'phone': 373105, 
        'computer': 377857, 
        'light_and_video': 382609, 
        'book_paper': 387361, 
        'money': 392104, 
        'mail': 396852, 
        'writing': 401598, 
        'office': 406362, 
        'lock': 411102, 
        'tool': 415870, 
        'science': 420611, 
        'medical': 425351, 
        'household': 430111, 
        'other_object': 434855
    },
    "symbols": {
        'id': 449583,
        'transport_sign': 444334, 
        'warning': 449083, 
        'arrow': 453851, 
        'religion': 458606, 
        'zodiac': 463352, 
        'av_symbol': 468119, 
        'gender': 472858, 
        'math': 477599, 
        'punctuation': 482342, 
        'currency': 487077, 
        'other_symbol': 491843, 
        'keycap': 496601, 
        'alphanum': 501383, 
        'geometric': 506154
    },
    "flags": {
        'id': 552605,
        'flag': 515634, 
        'country_flag': 520625,
        'subdivision_flag': 525362
    }
}

EMOJI_DATA = {
""", output_path)

    extracted_data = extract_emoji_data()

    current_emoji = None
    previous_emoji = None

    progress = 0
    clocks = ['üïõ', 'üïê', 'üïë', 'üïí', 'üïì', 'üïî', 'üïï', 'üïñ', 'üïó', 'üïò', 'üïô', 'üïö', 'üï°']
    clock_index = 0
    for data in extracted_data:
        string_data = data[0]
        current_emoji = data[1][4]
        
        for i in enumerate(clocks):
            if clock_index == 12:
                clock_index = 0
            print(f"{clocks[clock_index]}: {progress} [", data[1][4], "] ------> EMOJI_DATA{}")
            clock_index = clock_index + 1
            break
        
        if current_emoji == previous_emoji:
            continue        
        
        _write_data(string_data, output_path)
        
        previous_emoji = current_emoji
        progress = progress + 1

    ###############################


    ###############################

    _write_data(
"""
}
""",
    output_path)
    print("Finished extracting & compiling emoji data successfully.")

def generate_data():
    # Find the latest version at https://www.unicode.org/reports/tr51/#emoji_data
    emoji_source = get_unicode_emoji_test_file(15.0)
    emoji_sequences_source = get_unicode_emoji_variation_sequence_file('15.0.0')
    emojis = extract_emojis(emoji_source, emoji_sequences_source)
    # Find latest release tag at https://cldr.unicode.org/index/downloads
    github_tag = 'release-43-1'

    languages = {
        # Update names in other languages:
        'de': extract_names(github_tag, 'de', 'de', get_emojiterra_from_url('https://emojiterra.com/de/kopieren/')),
        'es': extract_names(github_tag, 'es', 'es', get_emojiterra_from_url('https://emojiterra.com/es/copiar/')),
        'fr': extract_names(github_tag, 'fr', 'fr', get_emojiterra_from_url('https://emojiterra.com/fr/copier/')),
        'ja': extract_names(github_tag, 'ja', 'ja', get_emojiterra_from_url('https://emojiterra.com/copypaste/ja/')),
        'ko': extract_names(github_tag, 'ko', 'ko', get_emojiterra_from_url('https://emojiterra.com/copypaste/ko/')),
        'pt': extract_names(github_tag, 'pt', 'pt', get_emojiterra_from_url('https://emojiterra.com/pt/copiar/')),
        'it': extract_names(github_tag, 'it', 'it', get_emojiterra_from_url('https://emojiterra.com/it/copiare/')),
        'fa': extract_names(github_tag, 'fa', 'fa', get_emojiterra_from_url('https://emojiterra.com/copypaste/fa/')),
        'id': extract_names(github_tag, 'id', 'id', get_emojiterra_from_url('https://emojiterra.com/copypaste/id/')),
        'zh': extract_names(github_tag, 'zh', 'zh', get_emojiterra_from_url('https://emojiterra.com/copypaste/zh/')),
    }

    github_alias_dict = get_emoji_from_github_api('https://api.github.com/emojis')
    cheat_sheet_dict = get_cheat_sheet('https://www.webfx.com/tools/emoji-cheat-sheet/')
    youtube_dict = get_emoji_from_youtube('https://www.gstatic.com/youtube/img/emojis/emojis-png-7.json')

    used_github_aliases = set()

    escapedToUnicodeMap = {escaped: escaped.encode().decode('unicode-escape') for escaped in emojis}  # maps: "\\U0001F4A4" to "\U0001F4A4"

    all_existing_aliases_and_en = set(item for emj_data in EMOJI_DATA.values() for item in emj_data.get('alias', []))
    all_existing_aliases_and_en.update(emj_data['en'] for emj_data in EMOJI_DATA.values())

    f = 0
    c = 0
    new_aliases = []
    for code, v in sorted(emojis.items(), key=lambda item: item[1]["en"]):
        language_str = ''
        emj = escapedToUnicodeMap[code]

        alternative = re.sub(r"\\U0000FE0[EF]$", "", code)
        emj_no_variant = escapedToUnicodeMap[alternative]

        # add names in other languages
        for lang in languages:
            if emj in languages[lang]:
                language_str += ",\n        '%s': '%s'" % (
                    lang, languages[lang][emj])
            elif 'variant' in v:
                # the language annotation uses the normal emoji (no variant), while the emoji-test.txt uses the emoji or text variant
                if emj_no_variant in languages[lang]:
                    language_str += ",\n        '%s': '%s'" % (
                        lang, languages[lang][emj_no_variant])

        # Add existing alias from EMOJI_DATA
        aliases = set()
        if emj in EMOJI_DATA and 'alias' in EMOJI_DATA[emj]:
            aliases.update(a[1:-1] for a in EMOJI_DATA[emj]['alias'])
        old_aliases = set(aliases)

        if emj_no_variant in EMOJI_DATA and 'alias' in EMOJI_DATA[emj_no_variant]:
            aliases.update(a[1:-1] for a in EMOJI_DATA[emj_no_variant]['alias'])

        # Add alias from GitHub API
        github_aliases = find_github_aliases(emj, github_alias_dict, v, emj_no_variant)
        aliases.update(shortcut for shortcut in github_aliases if shortcut not in all_existing_aliases_and_en)
        used_github_aliases.update(github_aliases)

        # Add alias from cheat sheet
        if emj in cheat_sheet_dict and cheat_sheet_dict[emj] not in all_existing_aliases_and_en:
            aliases.add(cheat_sheet_dict[emj][1:-1])
        if emj_no_variant in cheat_sheet_dict and cheat_sheet_dict[emj_no_variant] not in all_existing_aliases_and_en:
            aliases.add(cheat_sheet_dict[emj_no_variant][1:-1])

        # Add alias from youtube
        if emj in youtube_dict:
            aliases.update(shortcut[1:-1] for shortcut in youtube_dict[emj] if shortcut not in all_existing_aliases_and_en)
        if emj_no_variant in youtube_dict:
            aliases.update(shortcut[1:-1] for shortcut in youtube_dict[emj_no_variant] if shortcut not in all_existing_aliases_and_en)

        # Remove if alias is same as 'en'-name
        if v["en"] in aliases:
            aliases.remove(v["en"])

        # Store new aliases to print them at the end after the dict of dicts
        if emj in EMOJI_DATA:
            if 'alias' in EMOJI_DATA[emj]:
                diff = aliases.difference(a[1:-1] for a in EMOJI_DATA[emj]['alias'])
            else:
                diff = aliases
            for a in diff:
                new_aliases.append(f"# alias NEW {a} FOR {emj} CODE {code}")

        # Keep the order of existing aliases intact
        if emj in EMOJI_DATA and 'alias' in EMOJI_DATA[emj]:
            aliases = [a[1:-1] for a in EMOJI_DATA[emj]['alias']] + [a for a in aliases if f":{a}:" not in EMOJI_DATA[emj]['alias']]

        if any("flag_for_" in a for a in aliases):
            # Put the :flag_for_COUNTRY: alias as the first entry so that it gets picked by demojize()
            # This ensures compatibility because in the past there was only the :flag_for_COUNTRY: alias
            aliases = [a for a in aliases if "flag_for_" in a] + [a for a in aliases if "flag_for_" not in a]

        # Print dict of dicts
        alias = ''
        if len(aliases) > 0:
            alias_list_str = ", ".join([f"':{a}:'" for a in aliases])
            alias = ",\n        'alias': [%s]" % (alias_list_str, )
        variant = ",\n        'variant': True" if 'variant' in v else ''
        print(f"""    '{code}': {{  # {emj}
        'en': ':{v['en']}:',
        'status': {v["status"]},
        'E': {v["version"]:g}{alias}{variant}{language_str}
    }}""", end=",\n")
        if v["status"] == "fully_qualified":
            f += 1
        elif v["status"] == "component":
            c += 1



